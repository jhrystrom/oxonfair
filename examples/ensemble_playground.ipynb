{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blac0863/repos/oxonfair/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using the latest cached version of the module from /VData/resources/huggingface/modules/evaluate_modules/metrics/evaluate-metric--f1/34c46321f42186df33a6260966e34a368f14868d9cc2ba47d142112e2800d233 (last modified on Thu Mar 20 16:34:30 2025) since it couldn't be found locally at evaluate-metric--f1, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /VData/resources/huggingface/modules/evaluate_modules/metrics/evaluate-metric--precision/155d3220d6cd4a6553f12da68eeb3d1f97cf431206304a4bc6e2d564c29502e9 (last modified on Thu Mar 20 16:34:31 2025) since it couldn't be found locally at evaluate-metric--precision, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /VData/resources/huggingface/modules/evaluate_modules/metrics/evaluate-metric--recall/11f90e583db35601050aed380d48e83202a896976b9608432fba9244fb447f24 (last modified on Thu Mar 20 16:34:31 2025) since it couldn't be found locally at evaluate-metric--recall, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "import copy\n",
    "from typing import Any\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "import oxonfair\n",
    "from oxonfair import group_metrics as gm\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.modeling_outputs import (\n",
    "    ModelOutput,  # or just use dict if not subclassing\n",
    ")\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "CACHE_DIR = Path().cwd().parent / \".cache\"\n",
    "if not CACHE_DIR.exists():\n",
    "    CACHE_DIR.mkdir()\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = sigmoid(predictions)\n",
    "    predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "    return clf_metrics.compute(\n",
    "        predictions=predictions, references=labels.astype(int).reshape(-1)\n",
    "    )\n",
    "\n",
    "\n",
    "# 8. Configure training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"multilabel_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load tokenizer\n",
    "model_path = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 5112/5112 [00:00<00:00, 7477.75 examples/s]\n",
      "Map: 100%|██████████| 1230/1230 [00:00<00:00, 9025.01 examples/s]\n",
      "/tmp/ipykernel_2225716/18876404.py:131: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 00:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.626881</td>\n",
       "      <td>0.672358</td>\n",
       "      <td>0.708394</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.878815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.596805</td>\n",
       "      <td>0.677642</td>\n",
       "      <td>0.715872</td>\n",
       "      <td>0.595707</td>\n",
       "      <td>0.896768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.597215</td>\n",
       "      <td>0.679675</td>\n",
       "      <td>0.717765</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>0.899461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 5126/5126 [00:00<00:00, 8948.16 examples/s]\n",
      "Map: 100%|██████████| 1216/1216 [00:00<00:00, 8895.21 examples/s]\n",
      "/tmp/ipykernel_2225716/18876404.py:131: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='483' max='483' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [483/483 00:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.613230</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.703346</td>\n",
       "      <td>0.593848</td>\n",
       "      <td>0.862352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.594822</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.705100</td>\n",
       "      <td>0.592915</td>\n",
       "      <td>0.869644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.613584</td>\n",
       "      <td>0.669819</td>\n",
       "      <td>0.708530</td>\n",
       "      <td>0.588661</td>\n",
       "      <td>0.889699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 5116/5116 [00:00<00:00, 7376.72 examples/s]\n",
      "Map: 100%|██████████| 1226/1226 [00:00<00:00, 8712.17 examples/s]\n",
      "/tmp/ipykernel_2225716/18876404.py:131: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 00:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>0.670065</td>\n",
       "      <td>0.710968</td>\n",
       "      <td>0.595096</td>\n",
       "      <td>0.882875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663193</td>\n",
       "      <td>0.670881</td>\n",
       "      <td>0.717733</td>\n",
       "      <td>0.592379</td>\n",
       "      <td>0.910382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.620299</td>\n",
       "      <td>0.680261</td>\n",
       "      <td>0.720599</td>\n",
       "      <td>0.602144</td>\n",
       "      <td>0.897072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_full_data():\n",
    "    english_hatespeech = Path().cwd().parent / \"hatespeech-data\" / \"split\" / \"English\"\n",
    "    all_data = list(english_hatespeech.glob(\"*.tsv\"))\n",
    "    return (\n",
    "        pl.DataFrame(\n",
    "            pd.concat([pd.read_csv(f, sep=\"\\t\") for f in all_data]).drop(\n",
    "                columns=[\"city\", \"state\", \"country\", \"date\"]\n",
    "            )\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"gender\").replace(\"x\", None).cast(pl.Int8),\n",
    "            pl.col(\"age\").replace(\"x\", None).cast(pl.Int8),\n",
    "            pl.col(\"ethnicity\").replace(\"x\", None).cast(pl.Int8),\n",
    "        )\n",
    "        .drop_nulls()\n",
    "        .rename({\"label\": \"target\"})\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dataset(\n",
    "    features: pl.DataFrame, labels: pl.Series, feature_names: list[str] | None = None\n",
    ") -> Dataset:\n",
    "    if feature_names is None:\n",
    "        feature_names = features.columns\n",
    "    feature_dict = {feature: features[feature].to_list() for feature in feature_names}\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            **feature_dict,\n",
    "            \"target\": labels.to_list(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "@lru_cache\n",
    "def tokenize(text: str) -> dict[str, Any]:\n",
    "    return tokenizer(text, truncation=True)\n",
    "\n",
    "\n",
    "def preprocess_simple(example: dict[str, Any]) -> dict[str, Any]:\n",
    "    tokenized = tokenize(example[\"text\"])\n",
    "    labels = [float(example[key]) for key in [\"target\", \"gender\"]]\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def compute_loss_func(\n",
    "    outputs: ModelOutput | dict,\n",
    "    labels: torch.Tensor,\n",
    "    num_items_in_batch: int,  # noqa: ARG001\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Custom loss function for HuggingFace Trainer:\n",
    "    - Binary log loss for the first element\n",
    "    - Squared loss (MSE) for the remaining elements\n",
    "\n",
    "    Args:\n",
    "        outputs: ModelOutput or dict containing 'logits' of shape (batch_size, num_outputs)\n",
    "        labels: Tensor of shape (batch_size, num_outputs), ground-truth labels\n",
    "        num_items_in_batch: Total number of items in the accumulated batch (unused here)\n",
    "        num_classification_labels: Number of non-group based classification labels (default: 2)\n",
    "\n",
    "    Returns:\n",
    "        Scalar tensor representing the combined loss\n",
    "    \"\"\"\n",
    "    logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[\"logits\"]\n",
    "\n",
    "    log_loss = F.binary_cross_entropy_with_logits(logits[:, :1], labels[:, :1])\n",
    "\n",
    "    # Regression loss (MSE) for remaining outputs\n",
    "    if logits.shape[1] > 1:\n",
    "        mse_loss = F.mse_loss(logits[:, 1:], labels[:, 1:])\n",
    "        loss = log_loss + mse_loss\n",
    "    else:\n",
    "        loss = log_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "combined = get_full_data().sample(fraction=0.2)\n",
    "\n",
    "# 5. Prepare data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# 6. Metrics function\n",
    "# 7. Initialize model\n",
    "\n",
    "\n",
    "K = 5\n",
    "gss = GroupShuffleSplit(n_splits=K, train_size=0.8, random_state=110)\n",
    "all_features = combined.drop(\"target\", \"tid\", \"uid\", \"age\", \"ethnicity\")\n",
    "all_labels = combined[\"target\"]\n",
    "all_users = combined[\"uid\"]\n",
    "\n",
    "for train_index, test_index in gss.split(all_features, all_labels, groups=all_users):\n",
    "    train_features = all_features[train_index]\n",
    "    train_labels = all_labels[train_index]\n",
    "    train_groups = all_users[train_index]\n",
    "    test_features = all_features[test_index]\n",
    "    test_labels = all_labels[test_index]\n",
    "\n",
    "    # nested cross-validation\n",
    "    # Run oxonfair on an outer \n",
    "    # Min recall as a key metric for each test partition\n",
    "    # Key question: how big do we need to make the delta min recall to matter on the text\n",
    "    fair_ensemble = []\n",
    "    inner_gss = GroupShuffleSplit(n_splits=3, train_size=0.8, random_state=110)\n",
    "    for inner_train_index, validation_index in inner_gss.split(\n",
    "        train_features, train_labels, groups=train_groups\n",
    "    ):\n",
    "        inner_train_features = train_features[inner_train_index]\n",
    "        inner_train_labels = train_labels[inner_train_index]\n",
    "        inner_train_groups = train_groups[inner_train_index]\n",
    "        inner_validation_features = train_features[validation_index]\n",
    "        inner_validation_labels = train_labels[validation_index]\n",
    "        inner_validation_groups = train_groups[validation_index]\n",
    "        assert inner_validation_groups.shape[0] == validation_index.shape[0]\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_path,\n",
    "            num_labels=2,\n",
    "            problem_type=\"multi_label_classification\",\n",
    "        )\n",
    "\n",
    "        train_dataset = create_dataset(\n",
    "            inner_train_features,\n",
    "            inner_train_labels,\n",
    "        ).map(preprocess_simple)\n",
    "\n",
    "        validation_dataset = create_dataset(\n",
    "            inner_validation_features,\n",
    "            inner_validation_labels,\n",
    "        ).map(preprocess_simple)\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=validation_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "            compute_loss_func=compute_loss_func,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        trainer.train()\n",
    "        # Run oxonfair here? to merge heads etc.\n",
    "        val_output = trainer.predict(validation_dataset)\n",
    "        fpred = oxonfair.DeepFairPredictor(inner_validation_labels.to_numpy(), val_output.predictions, groups=np.array(validation_dataset[\"gender\"]))\n",
    "        fpred.fit(gm.accuracy, gm.equal_opportunity, 0.02, grid_width=75)\n",
    "        fair_network = copy.deepcopy(trainer)\n",
    "        fair_network.model.classifier = fpred.merge_heads_pytorch(fair_network.model.classifier)\n",
    "        fair_ensemble.append(fair_network)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'LABEL_0', 'score': 0.10932417958974838}\n",
      "{'label': 'LABEL_0', 'score': 0.037440285086631775}\n",
      "{'label': 'LABEL_0', 'score': 0.00524404039606452}\n",
      "{'label': 'LABEL_0', 'score': 0.9511734843254089}\n",
      "{'label': 'LABEL_0', 'score': 0.9632535576820374}\n",
      "{'label': 'LABEL_0', 'score': 0.9765505194664001}\n",
      "{'label': 'LABEL_0', 'score': 0.915313184261322}\n",
      "{'label': 'LABEL_0', 'score': 0.9852876663208008}\n",
      "{'label': 'LABEL_0', 'score': 0.982718288898468}\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "def majority_vote(lists: list[list[bool]]) -> list[bool]:\n",
    "    return [sum(sublist) > len(sublist)/2 for sublist in lists]\n",
    "\n",
    "def convert_score(score: float, threshold: float=0.5) -> bool:\n",
    "    return score > threshold\n",
    "\n",
    "def aggregate_scores(scores: list[list[dict]], threshold: float=0.5) -> list[bool]:\n",
    "    num_preds = len(scores[0])\n",
    "    # Convert to list[(pred0, pred0, pred0), (pred1, ...]\n",
    "    final_preds = []\n",
    "    for pred_index in range(num_preds):\n",
    "        pred_list = []\n",
    "        for score_list in scores:\n",
    "            score_dict = score_list[pred_index]\n",
    "            pred_list.append(convert_score(score_dict[\"score\"], threshold=threshold))\n",
    "        final_preds.append(pred_list)\n",
    "    return majority_vote(final_preds)\n",
    "\n",
    "\n",
    "def max_index_by_key(lst: list[dict], key: str=\"score\"):\n",
    "    if not lst:\n",
    "        return None\n",
    "    return max(range(len(lst)), key=lambda i: lst[i][key])\n",
    "\n",
    "def ensemble_predict(texts: list[str], ensemble: list[Trainer]) -> list[int]:\n",
    "    device = ensemble[0].model.device  # Get device from first model\n",
    "    pipes = [TextClassificationPipeline(tokenizer=tokenizer, model=trainer.model.to(device), device=device) for trainer in ensemble]\n",
    "    preds = [pipe(texts) for pipe in pipes]\n",
    "    return aggregate_scores(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.0040559242479503155},\n",
       "  {'label': 'LABEL_0', 'score': 0.31653323769569397},\n",
       "  {'label': 'LABEL_0', 'score': 0.8107593655586243}],\n",
       " [{'label': 'LABEL_0', 'score': 0.013930326327681541},\n",
       "  {'label': 'LABEL_0', 'score': 0.11571655422449112},\n",
       "  {'label': 'LABEL_0', 'score': 0.6770954132080078}],\n",
       " [{'label': 'LABEL_0', 'score': 0.03584609180688858},\n",
       "  {'label': 'LABEL_0', 'score': 0.18709571659564972},\n",
       "  {'label': 'LABEL_0', 'score': 0.8431380391120911}]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Statistical Parity</th>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.009136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity</th>\n",
       "      <td>0.016158</td>\n",
       "      <td>0.087214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity</th>\n",
       "      <td>0.083916</td>\n",
       "      <td>0.008741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Group Difference in False Negative Rate</th>\n",
       "      <td>0.083916</td>\n",
       "      <td>0.008741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized Odds</th>\n",
       "      <td>0.061629</td>\n",
       "      <td>0.027799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conditional Use Accuracy</th>\n",
       "      <td>0.021797</td>\n",
       "      <td>0.046344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Group Difference in Accuracy</th>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.031756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Treatment Equality</th>\n",
       "      <td>0.808340</td>\n",
       "      <td>0.771552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 original   updated\n",
       "Statistical Parity                               0.091000  0.009136\n",
       "Predictive Parity                                0.016158  0.087214\n",
       "Equal Opportunity                                0.083916  0.008741\n",
       "Average Group Difference in False Negative Rate  0.083916  0.008741\n",
       "Equalized Odds                                   0.061629  0.027799\n",
       "Conditional Use Accuracy                         0.021797  0.046344\n",
       "Average Group Difference in Accuracy             0.005622  0.031756\n",
       "Treatment Equality                               0.808340  0.771552"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpred.evaluate_fairness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_network.classifier = fpred.merge_heads_pytorch(fair_network.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=1, bias=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_network.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
